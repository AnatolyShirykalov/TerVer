\section{Центральная предельная теорема}
Самая интересная теорема теории вероятностей. Она говорит, что сумма случайных величин при каких-то условиях имеет нормальное распределение, то есть
\[
  \phi(x) = \frac1{\sqrt{2\pi}} e^{-\frac{x^2}2}.
\]
Похоже на колокол. Обозначают это распределение $N(0,1)$. У него $\E\xi = 0$, $\D\xi = 1$, $p_\xi = \phi$

Если же $\eta = a + \sigma\xi$, то $\E\eta = a$, $\sqrt{\D\xi} = \sigma$ "--- стандартное отклонение. Плотность тоже можно выразить
\[
  p_\eta(y) = \frac1{\sigma\sqrt{2\pi}}\exp\left\{ \frac{(y-a)^2}{2\sigma^2} \right\}.
\]

Обозначим меру $\nu$, которой отвечает функция плотности $\phi(x)$. То есть
\[
  \nu(B) = \int\limits_B \phi(x)\,dx.
\]

Пусть $S_n = \xi_1+\xi_2+\dots + \xi_n$. Обозначим $s_n = \frac{S_n - \E S_n}{\sqrt{\D S_n}}$. Тогда $\mu_{s_n}(B) = \P\{s_n\in B\}$. Будем доказывать, что $\mu_{s_n}$ сходится (в каком-то смысле) к $\nu$.

Что такое слабая сходимость 
\begin{Def}
$\frac{\xi_1 + \xi_2+\dots }\xi_n{n}\te 0$ по вероятности, если
\[
\forall\ \e>0\pau  \P\left\{ \frac{\xi_1+\dots+\xi_n}n>\e \right\} \te 0.
\]
\end{Def}

Пусть $\phi(x) = \phi$ "--- гладкая ($C^2$) и финитная функция. Обощначим $\mu(\phi) = \int\limits_{-\infty}^{\infty} \phi(x)\mu(dx) = \E \phi(\xi)$.
\begin{Def}
Последовательность мер $\mu_n$ называется сходящейся слабо к мере $\mu$. Если
\[
\forall\ \phi\pau \mu_n(\phi) \te \mu(\phi).
\]
\end{Def}

Мы будем доказывать как раз такую сходимость.

Пусть $J=[a,b]$, $\mu_n\te \nu$ слабо, $\nu$ "--- нормальное, то $\mu_n(J)\te \nu(J)$. Это можно увидеть, взяв индикатор этого интервала $I_{[a,b]}$, этот индикатор приблизив гладкими функциями сверху и снизу: $\phi_+(x)\ge J_{[a,b]}(x) \ge \phi_-(x)$. (Приближения легче строить так, чтобы функции отличались от индикаторов на маленьком отрезке и с ростом $n$ этот отрезок уменьшился).

Мы выясняли, что если у случайных величин есть плотности, то плотность суммы есть свёртка плотностей. Со свёрток удобно работать через преобразование Фурье.
Преобразование Фурье от функции плотности называется характирестической функцией случайной величины.

\begin{Def}
Пусть есть случайная величина $\xi$, её распределение $\mu_\xi$, её плотность $p_\xi(x)$. Тогда обозначают
\[
  f_\xi(t) = \E e^{it\xi} = \int\limits_{-\infty}^{\infty} e^{itx}\mu_\xi(dx) = \int\limits_{-\infty}^{\infty}e^{itx} p_\xi(x)\,dx
\]
Это и называют характеристических функций.
\end{Def}

\begin{Ut}
 Пусть $\xi$ и $\eta$ независимы. Тогда
  $f_{\xi+\eta}(t) = \E e^{it(\xi+\eta)} = \E (e^{it\xi} e^{it\eta}) = f_\xi(t) f_\eta(t)$.
\end{Ut}

Пусть есть гладкая финитная функция $\phi(t)$. Тогда преобразование Фурье будем обозначать волнами.
\[
  \Til \phi(t) = \int\limits_{-\infty}^{\infty} e^{itx}\phi(x)\,dx.
\]
Этот интеграл совсем не страшный, так как $\phi$ финитная функция. С другой стороны
\[
  \phi = \frac1{2\pi} \int\limits_{-\infty}^{\infty} e^{-itx}\Til\phi(t)\,dt.
\]
А этот интеграл ужасный? Можем сказать, что $\big|\Til \phi(t)\big| \le \frac{\const}{1+t^2}$. (Убывает на бесконечности быстрее второй степени.) Ничего ужасного здесь тоже нет.

Можем теперь записать
\[
  \mu(\phi) = \int\limits_{-\infty}^{\infty} \phi(x)\mu(dx) = \frac1{2\pi} \int\limits_{-\infty}^{\infty} \bigg(\int\limits_{-\infty}^{\infty} e^{-itx}\Til\phi(t)\,dt\bigg)\mu(dx).
\]
Есть асболютная сходимость интегралов, так как для $\Til\phi$ у нас есть оценка, а мера $\mu$ конечная (мера всего единица). Значит, можно менять порядок интегрирования.
\[
  \mu(\varphi) = \frac1{\pi} \int\limits_{-\infty}^{\infty} \bigg(e^{-itx}\mu(dx)\bigg) \Til\phi(t)\,dt = 
  \int\limits_{-\infty}^{\infty} \ol{f_\mu(t)} \Til\phi(t)\,dt.
\]

Если вы помните теорию обобщённых функций, знаете, что
\[
  (F,\phi) = \int\limits_{-\infty}^{\infty} \ol{F(x)} \phi(x) = F(\phi).
\]
Как со скалярным (эрмитовым) произведением, над одним из множителей ставят сопряжение.

В нашем случае
\[
  \mu(\phi) = (\mu,\phi) = \frac1{2\pi} (f_\mu,\Til\phi).
\]

Вот нам дано, что $f_n(t)\te f(t)$. Нужно показать слабую сходимость мер. Ну а что тут доказывать теперь
\[
 \phi(\phi) = \frac1{2\pi}\int\limits_{-\infty}^\infty \ol {f_\mu(t)}\phi(t)\,dt.
\]
Предельный переход под знаком интеграла сделаем по теореме Лебега. (Мы же имеем фиксированную $\phi$).

Таким образом мы доказали, что
\begin{Ut}
 Пусть $f_n\te f(t)$. Тогда $\mu_n\te \mu$ слабо.
\end{Ut}

Можно наконец объявить теорему.
\begin{The}
Пусть $\xi_1,\dots,\xi_n,\dots$ независимы и одинаково распределённые случайные величины, у которых существуют математические ожидания $\E\xi_k=a$ и дисперсии $\E\xi_k= \sigma^2$. Тогда обозначим
\[
  S_n = \xi_1 + \dots +\xi_n,\pau \E S_n = an, \pau \D S_n = n\sigma^2.
\]
Введё нормированную сумму
\[
  s_n = \frac{ S_n - na}{\sigma\sqrt{n}}.
\]
Утверждается, что $\mu_{s_n} \te \nu$ слабо.
\end{The}
\begin{Proof}
Достаточно показать сходимость характеристических функций. Напишем суммы
\[
  S_n - na = \RY k1n \xi_k - na = \RY k1n (\xi_k-a).
\]
Теперь нормированные суммы
\[
  \frac{S_n-na}{\sigma} = \RY k1n \underbrace{\frac{\xi_k-a}{\sigma}}_{\eta_k} =\RY k1n\eta_k.
\]
Видно, что $\E\eta_k = 0$, $\D\eta_k = 1$. Рассмотрим характеристическую функцию
\[
  f_k(t) = \E e^{it\eta_k} = \int\limits_{-\infty}^{\infty} e^{itk}\mu_k(dx).
\]
Продифференцируем это выражение
\[
  f'_k(t) =  \int\limits_{-\infty}^{\infty} ixe^{itx} \mu_k(dx).
\]
Если получившийся интеграл сходится равномерно, то слава богу. Ну так и будет. Остюда мы получим
\[
  f'_k(0) = i\E\eta_k = 0, \pau f''_k(0) = -1.
\]

Обозначим характеристическую функцию случайной величины $\eta_k$ через $g_k(t)$. Тогда
\[
  f_{s_n}(t) = \left[g\left(\frac t{\sqrt n}\right)\right]^n.
\]
Давайте по формуле Тейлора это вычислим.
\[
  f_{s_n}(t) = \left[1 - \frac12\frac{t^2}n + o\left( \frac1n \right)\right]^n \te e^{-t^2/2}.
\]
И вижу с удовольствием, что теорема доказана.
\end{Proof}

Это конечно хорошо. Но у нас количество испытаний всегда конечно. Давайте посмотрим, что будет для испытаний Бернулли.

Пусть имеется $n$ испытаний, $p$ вероятность удачи, $q=1-p$ вероятность неудачи. Исследуется число успехов $\mu = \e_1 + \dots + \e_n$. Посчитаем
\[
  \E\e_i = p,\pau D\e_i = \E\e_i^2 - (\E\e)^2 = p - p^2 = pq.
\]
Отсюда
\[
  \E\mu = np,\pau \D\mu = npq.
\]
И неплохо было бы это даже запомнить. Положим $\mu^* = \frac{\mu - np}{\sqrt{npq}}$. Мы хотим, чтобы
\[
  \P\{a\le \mu^*\le b\} = \nu\big\{[a,b]\big\} = \Phi(b) - \Phi(a).
\]

Когда говорят о нормальном распредлении, состовляются таблицы Лапласа, в которой записываются значения
\[
  \Phi(x) = \int\limits_{-\infty}^x \phi(y)\,dy
\]
функции распределения $N(0,1)$.

Например, пользуется спросом значение следующей вероятности
\[
  \P\big\{|\mu^*|\le 1.96\big\}  = 0.95.
\]
Ну и раскручивая назад
\[
  \P\big\{|\mu - np|\le 2\sqrt{npq}\big\}\approx 0.95.
\]
А из неравенства Чебышёва следовало, что
\[
  \P\big\{|\mu-np|\le 3\sqrt{npq}\big\} \ge \frac 89.
\]
То есть мы уточнили неравенство Чебышёва.

Если монеты бросались $n=100$ раз, а $\mu=70$. Предположим, что $p=\frac12$. Тогда $npq = 25$, $\sqrt{npq} = 5$ и  $\E\mu = 50$. Скажем «мошенничать изволите».

Пирсон бросал монету $n=24\,000$ раз. При этом получилось $\mu=12\,012$. В этом случае $\sqrt{npq} = \sqrt{6000} \approx 78$. Отсюда
\[
  \mu^* = \frac{12}{78} = 0.155 = \xi\sim N(0,1).
\]
Получилось так у Пирсона. Чему равна вероятность того, что
\[
  \P\big\{|\xi|\le 0.155\big\} = \int\limits_{-0.155}^{0.155} \frac1{\sqrt{2\pi}} \underbrace{e^{-x^2/2}}_{\approx 1}\,dx \approx \frac18.
\]

Мог ли Пирсон получить такой результат? Дело в том, что Пирсон сначала 6\,000 раз, оказалась слишком большая разница. Решил ещё побросать. Бросать монету легко, а сбиться со счёта ещё легче.

\subsection{Наблюдение физических величин}
Физик наблюдает величину $a$, но получается $a + \delta_i$, $\delta_i$ "--- ошибка. Тогда
\[
  \ol x = \frac1n \RY i1n x_i = a + \frac1n \RY i1n \delta_i.
\]
Если мы наделим ошибки $\delta_i$ душой, которая заключается в том, что они станут независимыми случайными величинами, $\E\delta_i = 0$, $\D \delta_i = \E \delta_i^2 = \sigma^2$. Осюда
\[
  \D\left( \frac1n \RY i1n \delta_i \right) = \frac{\sigma^2}n.
\]
Тогда $\sqrt{\D(1/n \Sigma \delta_i)} = \frac\sigma{\sqrt n}$. Всё решает один единственный параметр $\sigma$. Возникает вопрос, при каком $n$ следующая вероятность
\[
\P  \big\{|\ol x - a| \le 2s/\sqrt{n}\big\} = 0.95.
\]
