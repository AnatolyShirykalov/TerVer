\section{Лекция 1}

Зовут меня Валерий Николаевич Тутубалин. Из учебников рекомендую Б.",Н.",Севастьянов, Тутубалин, Тюрин, Макаров.

Говорят про вероятность наводнений, землетрясений "--- что-то физическое. Есть вероятность обвала рубля "--- чистая математика.

Какие события называются случайными. Сейчас будет ещё не определение, а мотивировка. Итак, случайности
\begin{roItems}
\item Воспроизводимость, массовость. Событие $A$ может произойти большое число раз. Опыт можно сделать много раз, в теории бесконечное число раз.
\item Статистическая устойчивость. Что это такое. Давайте нарисуем схему.
% рис 1
Обозначим $n$ число опытов, $\mu_A$ "--- число наступлений $A$. Величину $\frac{\mu_A}n$ называют частотой (экономисты называют частостью).
% рис 2
На втором рисунке показана динамика частоты. В какой момент она стабилизируется? Есть некоторая \textit{непредсказуемость}.
\end{roItems}
Величина частоты есть что-то вроде вероятности, то есть $\frac{\mu_A}n\approx \P(A)$.

Так математики, конечно, говорить не могут. Давайте попробуем ввести основные понятия.

Рассмотрим множество $\Omega = \{\omega\}$ "--- множество элементарных событий. Это множество возможных исходов опытов, которыми мы планируем заниматься. Полный список исходов. Мы сейчас предположим, что $\Omega$ не более чем счётно. Случай, когда $\Omega$ более чем счётно, относится к теории Колмогорова, которой мы в основном и будем заниматься. Но сейчас мы позанимаемся не более чем счётными. Отображение $\omega\to P(\omega)\ge0$ "--- вероятность элементарного исхода.
 Если сложить все вероятности, получим (складываем частоты) $\sum\limits{\omega\in\Omega} P(\omega) = 1$.

\begin{Aks}
$\sum\limits_{\omega\in\Omega} \P(\omega) = 1$.
\end{Aks}

\begin{Def}
Событием $A$ называется любое подмножество $\Omega$. Его верятностью называют $\P(A) = \sum\limits_{\omega\in A}\P(\omega)$.
\end{Def}

Рассмотрим пример: студенты на экзамене. Всего $N$ билетов, столько же и студентов. $n$ билетов счастливые для всех. Вероятность того, что первый счастливый: $\frac nN$. А то, что второй счастливый? Надо посмотреть как-то иначе.

Пусть $|\Omega|= N(\Omega)<\infty$. Пусть также события все одинаковые. Тогда $\P(\omega) = \frac1{N(\Omega)}$. Тогда $\P(A) = \frac{N(A)}{N(\Omega)}$.

Давайте оформим этот вывод как заклинание. 

Что же считать элементарным событием в случае студентов? Пусть студенты будут занумерованы $1,2,\dots,N$, билеты будут подписаны $i_1,i_2,\dots,i_N$. Обозначим
\[
  \begin{pmatrix}
1,&2,&\dots&,N\\
i_1& i_2&\dots &i_N
\end{pmatrix} = \omega
\]
Всякая $\omega$ "--- подстановка (или перестановка). В качестве $A_k$ будем брать события
\[
  A_k = \{k\text{-й счастливый}\} = \{\omega\colon i_k = 1,\dots,n\}.
\]

В данном случае $|\Omega| = N!$, $|A_k| = n (N-1)!$, $\P(A_k) = \frac{n(N-1)!}{N!} = \frac nN$.

То обстоятельство, что в данном случае $\P(\omega) = \frac1{N!}$, есть ли это математический феномен? Доказываемо ли это? Не смогли мы этого доказать. Вдруг лучшие билеты внизу стопки? Таким образом, такое предположение равновероятности элементарных событий "--- это экспериментальный факт. Эта информация берётся из частот.

Пусть $|\Omega|=N!$, а $N$ большое, например, $N=25$. Все частоты будут равны почти нулю. Это уже не экспирементальный факт. Если билеты на столе раскладываются нечестно, то равномерного распределения не будет, но мы не знаем, как раскладывали. Мы сталкиваемся с тем, что выводы основаны непонятно на чём. 


Пусть есть $\Omega$, вероятности $\P(\omega)$, $A\subset \Omega$, $\P(A) = \sum\limits{\omega\in A}P(\omega)$. Вот все наши величины.

\begin{Def}
Противоположное событие $\ol A$ состоит из таких $\omega$, что не входят в $A$, то есть это дополнение множества $A$:
\[
  \ol A = \{\omega\colon \omega\not\subset A\}/
\]
\end{Def}

Заметим, что $\P(A) + \P(\ol A) = 1$. Ну это уже математическая теорема.

% рис 3

Пусть есть два события $A$ и $B$. С двумя событиями можно много всего сделать.
\begin{Def}
 $A\cup B = \{\omega\colon \omega\in A\text{ или }\omega\in B\}$ "--- сумма событий $A$ и $B$.
\end{Def}

\begin{Def}
  $A\cap B = AB = \{\omega\colon \omega\in A\text{ и }\omega\in B\}$ "--- пересечение событий.
\end{Def}

Что происходит с вероятностями $\P(A\cup B) = \P(A) + \P(B) - \P(AB)$. Если события удовлетворяют $AB=\q$, то $\P(A+B) = \P(A) + \P(B)$.

\begin{Ut}
Пусть $A_1,\dots, A_n,\dots$ таковы, что $A_iA_j=\q$ при $i\ne j$. Тогда
\[
  \P(A_1 + A_2 + \dots + A_n +\dots) = \rY i1 \P(A_i).
\]
\end{Ut}
Это будет верно так как $\omega \in A_i\iff \omega \not\in A_j$ при $i\ne j$.

У Колмогорова это утверждение будет основной аксиомой.

Бывают ещё случаи, когда списков много. Пусть снова $N$ студентов, $N$ билетов. $p_1,\dots, p_N$ должны в одном списке сходятся к $\frac nN$. Но с какой скоростью?

Займёмся другими вопросами. Пусть $A$ и $B$ "--- два способа изготовления цемента. Проводим опыт.
%рис 4
Берём два куска цемента, засовываем в тиски. Кто не сломается, то победил. Пусть $A$ классический способ изготовления цемента, $B$ классический плюс дополнительный.

Будем проводить $n=10$ попарных сравнений. Сосоставим событиям числа $A\sim 0$, $B\sim 1$. Тогда в наших обозначениях $\omega = (\e_1,\e_2,\dots,\e_n)$, $\e_i = 0,1$. Чтобы $B$ было лучше, нужно выпадание $\mu(1)=7,8,9,10$ побед $B$. Будем считать, что $6$ "--- это ещё плохо, неубедительно. Будем говорить $A=B$, если все $\P(\omega)$ одинаковы и равны $2^{-10}$. Если $A=B$, то $4\le \mu(1) \le 6$ (никто не одержал 7 и более побед), это правильное решение.

$\mu(1) = \RY i1{10}\e_i$, $\P\{\omega\colon 4\le \mu\le 6\} = \P\{\mu=4\} + \P\{\mu = 5\} + \P\{\mu = 6\}$. При этом $\P\{\mu=k\} = C_{10}^k$ и $\mu(1) = \frac{672}{1024}\approx \frac23$.
Очень большая вероятность ошибочного решения в выборе между $A$ и $B$.

А данное решающее правило, то есть $n=10$ и $\mu\ge 7$ с какой вероятностью будет выдавать правильное решение?

Пусть вероятность $\P\{\text{победы }B\}\ge 0.7$, то есть $\P\{\e_1=1\} = 0.7$. А можем ли мы считать испытания независимыми (вскоре дадим определение независимости)?

\subsection{Условная вероятность}
Вероятность того, что случится событие $B$ при условии того, что случилось событие $A$, обозначается черех $\P(B\mid A) = \P_A(B)$.
%рис 5
Чтобы такую вероятность посчитать, надо взять события, в которых наступило $A$ и вычислить частоту события $B$.
\[
  \frac{\mu(AB)}{\mu(A)} = \frac{\mu(AB)/n}{\mu(A)/n}\approx \frac{\P(AB)}{\P(A)}.
\]
Такая вот мотивация к математическому определению условной вероятности.
\begin{Def}
  $\P(B\mid A) = \frac{\P(AB)}{\P(A)}$ ($\P(A)>0$). Или $\P(AB) = \P(A)\cdot \P(A\mid | B)$ (теорема об умножении вероятностей).
\end{Def}

Рассмотрим первых двух студентов: первый и второй. Может быть они оба счастливы (1 сч, 2 сч). Если первый уже вытащил счастливый билет, то мы знаем, сколько второму осталось счастливых билетов и сколько осталось билетов вообще. И условную вероятность посчитать проще чем вероятность пересечения. Используем это.
\[
  \P(1\text{сч 2 сч}) = \P(\text{1 сч}) \P(\text{2 сч}\mid\text{1 сч}) = \frac nN \frac{n-1}{N-1}.
\]

Вероятность, что первый несчастен, а второй счасливый
\[
  \P(\text{1 несч 2 сч} = \frac{N-n}N \frac n{N-1}.
\]
При этом $\P(\text{2 сч}) = \frac{n(n-1) + n(N-n)}{N(N-1)} = \frac nN$.

Пусть в двух карманах $120$, в левом вдвое больше, чем в правом.
\[
  x+ y =120, x = 2y.
\]
В левом $2x$, в правом $x$. $2x + x = 120$. Началась какая-то математика.
