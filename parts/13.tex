\section{Регрессионный анализ}
Математику я всю рассказал. А какие ожидания возлагаются на эту науку всеми, кроме математиков.

Хотим найти линейную зависимость $y = \RY i1n c_i x_i + \delta$. Делаем кучу измерений
\[
  y_j = \RY i1n c_i x_{ji} + \delta_j,\quad j=1,2,\dots,N\gg n.
\]
Будем считать, что $j$ номер строчки, все $y_j$ вместе составляют столбец. Ничего не остаётся, кроме как написать
\[
  Y = \RY i1n c_i X_i + \delta
\]
Вся математика сводится в ортогональном проектировании вектора $Y$ на линейную оболочку системы $\{X_i\}$. На всякий случай я ещё раз выпишу нашу математику.

Столбец $Y$ называют столбцом значений объясняемой переменной. Столбцы $X_1,X_2,\dots, X_n$ "--- столбцы значений объясняющих переменных. Из это столбцов запишем матрицу $X$.
\[
  Y = X C + \delta.
\]
Как же нам найти оценку $\hat C$ для вектора $C$. Разность $Y$ и его проекции должна быть ортогональна всем векторам линейной оболочки, я это запишу так
\[
  Y - X \hat C\perp X.
\]
Эта запись означает, что левый вектор ортогонален всем столбцам матрицы $X$. Как это ещё записать
\[
  X^T(Y-X\hat C) = 0.
\]
Здесь написано, что $X^T$ имеет своими строчками ортогональные вектору $Y-X\hat C$ строчки. Отсюда автоматически следует, что 
\[
  \hat C =  (X^T X)^{-1} X^T Y.
\]
Если подставить вместо $Y$ его представление $Y = XC + \delta$, получим
\[
  \hat C = C + (X^TX)^{-1}\delta.
\]
Мы не можем получить само $C$, мы можем получить $\hat C$, то есть $C$, но с ошибкой
\[
  (X^TX)^{-1}\delta.
\]

Бывает такое, что $y_1,y_2,\dots,y_N$ все объясняются только одной константой. Например, закон всемирного тяготения. Если бы не было ошибок, все $y_j$ должны были бы получиться одинаково. В этом случае пишем нашу священную величину
\[
  \ol y = \frac1N\RY j1Ny_j.
\]

В 90-х годах несколько групп намерили значения констант Ньютона. Значения получились близкие, но доверительные интервалы не пересекаются. Можно как-то посчитать среднее, но мы не знаем, с какими весами.

Описанная схема была совершенно нереализуема, пока не было компьютеров. А теперь пожалуйста.

Пусть $y$ "--- прочность стали, объясняемая переменная. $x_i$ "--- химический состав. Строим регрессию $y$ на $x_i$.

Или же $y$ "--- медицинский показатель, $x_i$ "--- дозировка лекарств. Опять регрессионный анализ.

\subsection{Шанс}
Рассмотрим случай, когда $x_1,\dots,x_n$ "--- значения показателей. А наблюдения $z$ принимают два значения $\{1,0\}$ удача или неудача. Хотим $p = p(x_1,\dots,x_n)$ "--- вероятность удачи. Линейную функцию искать неудобно. Вводят так называемый логшанс
\[
L =  \mathrm{Logchance} = \ln\frac1{1-p}.
\]
Тогда значения уже меняются от $-\infty$ до $+\infty$.

Тогда $L = c_0 + \sum c_i x_i$. Можно интерпретировать $x_1=1$. Это называется логистической регрессией.

Поделим эксперименты на две части. Одна будет обучением, а другая экзаменом. Случайное деление такого сорта никакого смысла не имеет. Экзамен будет сдаваться. Вы сделайте вот что. Возьмите два на проверку, а остальные на выборку. Частая ошибка делать такое деление случайно, в этом нет смысла.

\section{Многомерное нормальное распределение}
Одномерная случайная $\xi_1$ распределена нормально $N(0,1)$, если её плотность
\[
  p_{\xi_1}(x) = \frac1{\sqrt{2\pi}}e^{-\frac{x^2}2}.
\]
Пусть теперь $\xi = (\xi_1,\dots,\xi_n)$. Пусть у этой системы матрица ковариации $C_\xi = E$ единичная. Тогда
\[
  p_\xi(x_1,\dots,x_n) = \left( \frac1{\sqrt{2\pi}} \right)\left\{ -\frac{x_1^2+\dots +x_n^2}{2} \right\} = p_\xi(x) = \left( \frac2{\sqrt{2\pi}} \right)^n\exp\left\{ -\frac{(x,x)}2 \right\}.
\]
И наконец общий случай сводится к замене $\eta = a\xi + b$. Вектор $b$ есть математическое ожидание вектора $\eta$. А что происходит с матрицей ковариации.

Пусть вообще $\xi$ "--- столбец, причём $\E\xi = 0$, то есть $\E\xi_1=\dots=\E\xi_n=0$. Посмотрим
\[
  \E\xi_i\xi_j = \cov(\xi_i,\xi_j).
\]
И составляем из ковариаций матрицу. Как проще это сделать. Составить матрицу всевозможных компонент $\xi\xi^T$. Тогда $C_\xi = \E\xi\xi^T$. Пусть теперь $\eta = A\xi$, где $\det A \ne 0$. Тогда, так как $A$ предполагается постоянной, имеем
\[
  C_\eta = \E(\eta\eta^T) = \E(A\xi\xi^TA^T) = A\E(\xi\xi^T)A^T = A C_\xi A^T.
\]
Вдохновясь этим законом, вычислим, какова плотность вектора $\eta$. Я напомню такую формулу для $\eta = f(\xi)$, где $f\colon \R^n\to\R^n$ взаимнооднозначно. Она выглядит следующим образом
\[
  p_\eta(y) = p_\xi\big(f^{-1}(y)\big) |\text{якобиан }f^{-1}\text{ в точке }y|.
\]

Для отображения $\eta = A\xi + b$ имеем соответствующее преобразование в $\R^n$ вида $y = Ax +b$ или $x = A^{-1}(y-b)$. Таким образом,
\[
  p_\eta(y) = \left( \frac1{\sqrt{2\pi}} \right)^n\exp\left\{ -\frac{\big(A^{-1}(y-b),A^{-1}(y-b)\big)}{2} \right\}\frac1{|\det A|}.
\]
Заметим, что $(A^{-1})^TA^{-1} = (A A^T)^{-1} = C_\eta^{-1}$, а также $|\det A| = \sqrt{\det C_\eta}$. Поэтому
\[
  p_\eta(y) = (2\pi)^{-n/2}\frac1{\sqrt{\det C_\eta}} \exp\left\{ -\frac{\big(C_\eta^{-1}(y-b),(y-b)\big)}2 \right\}.
\]
Поверхности уровня у неё эллипсоиды.

Пусть есть две компоненты $\eta_1,\eta_2$. Есть плотность $p_{\eta_1,\eta_2}(y_1,y_2)$. Хочу плотность отдной компоненты, как это сделать. Ответ
\[
 \int\limits_{-\infty}^{+\infty} p_{\eta_1,\eta_2}(y_1,y_2)\,dy_2 = p_{\eta_1}(y_1).
\]

Как доказать, что компонента нормального вектора нормальна. Нужно воспользоваться преобразованием Фурье.
\[
  f_\xi(t) = \int\limits_{-\infty}^{+\infty} e^{itx}p_\xi(x)\,dx = \E e^{i(t,\xi)}.
\]
Когда $t,\xi$ "--- одномерные, запись в виде скалярного произведения $(t,\xi)$ ни к чему, но возможна. Итак обобщение
\[
  f_\xi(t) = \E e^{i(t,\xi)} = \int\limits_{\R^n} e^{i(t,x)}p\xi(x)\,dx.
\]

Для станлартной нормальной случайной величины
\[
  f_\xi(t) = \E e^{i(\xi,t)} = \prod\limits_{i=1}^n e^{-\frac{t_i^2}2} = e^{-\frac12(t,t)}.
\]

Для общего случая нормальной случайной величины
\[
  f_\eta(t) = \E\exp\left\{ i(t,A\xi+b) \right\} = e^{i(t,b)} \E\exp\big\{i(t,A\xi)\big\} = 
  e^{i(t,b)}\exp\left\{ -\frac{(A^Tt,A^Tt}2 \right\} = e^{i(t,b)}\exp\left\{ -\frac{(C_\eta t,t)}{2} \right\}.
\]

Чтобы получить характеристическую функцию только по части компонент, надо просто занулить соответствующие $t_i$.

\begin{Ut}
 Если нормальные случайные величины не кореллируют, то они независимы.
\end{Ut}
\begin{Ut}
  Любой подвектор нормального вектора нормален
\end{Ut}

Пусть мы исследуем $p$ через $\ln \frac{p}{1-p}$. Есть больные, есть здоровые. Ищем шанс, как функцию каких-то параметров.
