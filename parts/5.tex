\section{Лекция 5}
Мы сегодня заканчиваем введение в теорию вероятностей. Главная цель введения: показать, что вероятность это не совсем то, что подсказывает нам интуиция. На примере медицинских исследований: что может сказать врач больному о лекастве? Что среди всех, кто принимал эти лекарства 96\% выздоровели. Но это не значит, что данный больной будет излечен с вероятностью 95 \%. Мы установили, что
\[
  \P \left\{ |\ol x- a|\le\frac{3s}{\sqrt n}\right\} \ge \frac89,\qquad
s^2 = \frac1{n-1} \RY i1n (x_i-\ol x)^2.
\]

Позанимаемся логикой. Пусть все $A$ суть $B$, все $B$ суть $C$. Отсюд вывод: все $A$ суть $C$. Теперь немного это изменим. Пусть все $A$ суть $B$ и некоторые $B$ суть $C$. Вытекает ли отсюда, что некоторые $A$ суть $C$? Да нет же. (Например $A\subset B$ и $A\cap C=\q$.)

Пусть если гипотеза $H$ верна, то $S$ невозможно. Пусть также $S$ в опыте наступило. Отсюда какой вывод? Вывод: $H$ неверна. Я прошу вас заметить, что если мы попадаем в вероятностную ситуацию, такой логикой мы пользоваться не будем. Напишем следующим образом: пусть если $H$ неверна, то $S$ маловероятна; пусть также $S$ в опыте наступило. Отсюда хочется сказать: $H$ маловероятно. Но почему? На самом деле так не получится. Мы поэтому вводим понятие значимости статистической гипотезы.

Пусть есть $\Omega = \{\omega\}$. Но сами $\omega$ не наблюдаются. Но есть отображение $\Omega\to X=\{x\}$, причём иксы уже наблюдаются. Кроме того, пусть мы знаем $\P\{x\in A \subset X\mid H\}$ (черта заменяет слова: «если верна $H$»). Формально, уровень значимости $\alpha$ "--- это число из $[0,1]$. Мы это число задаём заранее, то есть до эксперимента. Чаще всего в качестве $\alpha$ выбирают одно из трёх: $0.05, 0.01, 0.001$. Для этого $\alpha$ находим множество $S\subset X$, для которого
\[
  \P\{x\in S\mid H\} \le \alpha.
\]
При эксперименте у нас либо $x$ попало в $S$, либо нет. Если $x\in S$, то говорят, что гипотеза $H$ отклоняется на уровне значимости $\alpha$. Если же $\alpha\not\in S$, то $H$ не отклоняется.

$\alpha$ "--- ограничение сверху вероятности зря обидеть нашу гипотезу.

На примере булочек. Было у нас $1\,000$ булочек, $10\,000$ изюминок. $x$ изюминок в эксперименте. Мы рассуждали в терминах $S = \{x=0\}$. Тогда если $x\in S$, то покупатель идёт жаловаться. Пусть $\lambda_0=10$, $0\le a\le 1$, $\lambda_a = 10(1-a)$. Вероятность обвинения
\[
  \P\{x\in S\mid H_0\} \approx 0.5\cdot 10^{-4}.
\]
Гипотезу мы сейчас обозначим. Пусть $A_k$ "--- событие типа $k$-й недоволен. Тогда
\[
  \P(A_1+A_2+\dots+A_{1\,000}) \approx \sum \P(A_i).
\]
Вероятность того, что $k$-й недоволен есть $0.05$. Тогда вероятность не получить жалобу за год $(0.95)^{365}\approx 0$.

Так вот обозначаем $H_0$  "--- основная гипотеза (ничего не воруют). У нас целое семейство гипотез $H_a$, $0\le a\le 1$. Естественно жаловаться когда изюминок не ноль, но слишком мало, то есть $S = \{x\le k\}$. Вероятность ограничена уровнем значимости $\P\{x\in S\mid H_0\}\le \alpha$. $\P\{\mu = x\} = \frac{\lambda^x}{x!}e^{-\lambda}$.1

Выпишем таблицу вероятности обвинения неповинного человека, который на самом деле ничего не воровал.

\begin{tabular}[H]{|c|c|c|c|}
\hline 
Доля $a$ & $\alpha=0.01$ & $\alpha=0.001$& $\alpha = 0.15$\\\hline
 & $S=\{x\le 3\}$& $S \le x\le 13\} $ & $S = \{x\le 6\}$  \\\hline
 0.0 & 0.020 & 0.00050 & 0.13 \\\hline
 0.1 & 0.021 & 0.0013  & \\\hline
 0.2 & 0.042 & 0.0031  & \\\hline
 0.5 & 0.27  & 0.041   & 0.76 \\\hline
 0.7 & 0.65  & 0.20 & \\\hline
 1   & 1     &  1 &  \\\hline
\end{tabular}

Здесь у нас выписана некая функция, обозначим её $\beta(a)$. Назовём функцией мощности.

Поставим камеры видеонаблюдения. Пусть они показали, что $80\,\%$ честных людей.  Из 0.8 честных 0.13 по нашему критерию обвинения на основе изюминок будут объявлены виновными.

Если будем слишком решительно поступать на основе статистики, можем прийти вот к такому абсурду. На этом введение в теорию вероятностей закончено.

\section{Аксиматика Колмогорова}

Рассмотрим мысленный эксперимент. На отрезок $[0,1]$ случайно бросается точка. Как ввести пространство событий и как ввести вероятность? Проще склеить отрезок в окружность, вбить в центр окружности гвоздить и прицепить туда стрелку. Где стрелка остановилась, то число на отрезке и выпало.

Так что же будет в роли $\omega$. Для любого физического опыта $\omega$ можно считать рациональным числом. Но что такое $\P(\omega)$? Они должны быть все одинаковы, если чисто случайно бросаются точки. Если $\P(\omega)>0$, то $\sum\limits_{\omega\in\Q}\P(\omega) = \infty$; а если $\P(\omega) = 0$, $\sum \P(\omega) = 0$. Всё это нехорошо.

Тогда решаемся сделать следующее. Пусть $\{\omega\}$ "--- все вещественные числа на отрезке, а вероятность определим $\P\big\{\omega\in[\alpha,\beta]\big\} = |\alpha - \beta|$ как длину отрезка. Теперь обратите внимание, что здесь потребуем.

У нас будет $\Omega$ "--- множество элементарных событий. Есть какие-то подмножества $A_i\subset \Omega$, обладающие вероятностью, то есть на которых определена $\P$. Так вот мы потребуем счётной аддитивности
\[
  \P(A_1+A_2+\dots ) = \rY i1 \P(A_i).
\]
Мы в качестве $\P$ на отрезке будем брать меру Лебега. Есть класс подмножеств $\mathfrak B$ этого отрезка, на котором мера Лебега определена.

В общем случае $\Omega = \{\omega\}$ "--- какое-то множество (в весеннем семетре, это будут, например, функции вещественной переменной), $\mathfrak B$ "--- сигма-алгебра подмножеств $\Omega$. Что за сигма-алгебра:
\begin{roItems}
  \item $\q,\Omega\in \mathfrak B$;
  \item если $A\in\mathfrak B$, то $\ol A = \Omega\setminus A\in\mathfrak B$;
  \item если $A_1,A_2,\dots,A_n,\dots\in\mathfrak B$, то и $\bigcup\limits_i A_i, \bigcap i A_i \in\mathfrak B$.
\end{roItems}
И есть у нас третий объект: счётно аддитивная функция на $\mathfrak B$: для непересекающихся $A_i$ имеем $\P(A_1+A_2+\dots) = \sum \P(A_i)$.

\begin{Def}
  Тройка $(\Omega,\mathfrak B,\P)$ называется вероятностным пространством.
\end{Def}
Элементы $\mathfrak B$ называют событиями.

Вот у нас $[\alpha,\beta]\in\mathfrak B$. Давайте введём понятие наименьшей $\sigma$-алгебры. Возьмём все $\sigma$-алгебры, содержащии все отрезки. Хотя бы одна такая есть: все подмножества. Наименьшей назовём пересечения всех таких $\sigma$-алгебр. Наименьшая $\sigma$-алгебра, содержащая отрезки, называется $\sigma$-алгеброй борелевских подмножеств.

Что входит в борелеские множества? Одноточечные множества $\{\omega\}$ входят, канторовское множество входит. Пример неборелевского множества вообще сложно привести, хотя и можно. Раз входят все точки, то вероятность точки есть нуль. $\P\{\text{рациональна}\} = 0$, $\P\{\text{иррациональна}\} = 1$. Физику это понравится? Это недостаток такой аксиоматики.

Теперь обсудим, зачем нам счётная аддитивность? Если в дискретной теории мат ожидания считаются через ряд, а у нас тут будут некие интегралы. Для интеграла нужна счётная аддитивность меры. Чтобы считать интегралы, надо обсудить, какие будем брать функции.

\begin{Def}
  Случайной величиной называется любая измеримая функция $\xi(\omega)\colon \Omega\to \R$.
\end{Def}
Что это значит. На $\Omega$ есть какая-то $\sigma$-алгебра $\mathfrak B$, на числовой прямой $\R$ есть борелевская $\sigma$-алгебра. Функция измерима, если для любого $B$ борелевского $\xi^{-1}(B) = \big\{\omega\colon \xi(\omega)\in B\big\}\in\mathfrak B$.

Давайте покажем, как можно построить интеграл Лебега.
Пусть $\xi(\omega)$ "--- измеримая функция, принимающая не более чем счётное число значений. Тогда её можно записать в виде
\[
  \xi(\omega) = \rY i1 a_i J_{A_i}(\omega),\qquad
  A_i A_j = \q \Leftarrow i\ne j,\qquad
  A_1+A_2+\dots = \Omega.
\]
Тогда
\[  
  \E\xi = \int\limits_\Omega \xi(\omega)\,\P(d\omega) = \sum\limits_{\{A_i\}} a_i \P(A_i).
\]
Это то, что мы уже писали. Формула имеет смысл, если ряд сходится. Единственное, что здесь может смущать, это независимость мат ожидания от выбора разбиения $\{A_i\}$, с помощью которого мы представляем $\xi(\omega)$. (Мы же можем разбить одно $A_i$ на несколько частей.)

Пусть $\xi(\omega) = \sum\limits_{\{A_i\}} a_i J_{A_i}(\omega) = \sum\limits_{\{B_i\}}b_i J_{B_i}(\omega)$. Тогда введём множества $D_{ij} = A_i B_j$. Некоторые из них могут быть пустыми, неважно. Тогда
\[
  \xi(\omega) = \sum\limits_{D_{ij}} d_{ij} \P(A_iB_j) = \
 \sum\limits_{\{A_i\}} a_i \sum\limits_{\{B_j\}} \P(D_{ij}) = \sum\limits_{\{A_i\}} a_i \P(A_i).
\]

Ну хорошо. Тогда возникает мысль, что интеграл обладает свойством линейности, а именно $\E(\xi +\eta) = \E\xi + \E\eta$. Для счётнозначных случайных величин это легко уже можем проверить. А также $\E c\xi = c\E\xi$.

Теперь нужно с помощью предельного перехода определить мат ожидание для произвольной случайной величины, конечно, измеримой.

Если $\big|\xi(\omega)\big|\le \e$, то и $|\E\xi|\le \e$. Это очевидно, так как сумма вероятностей элементов разбиения равна единице. Если $\xi_n\rsh[] n \xi$, причём $\xi$ измерима, то можно сделать предельный переход под интегралов. Давайте посмотрим
\[
  |\E\xi_n - \E\xi_m| = \big|\E(\xi_n-\xi_m)\big|\te 0.
\]

Пусть $\xi(\omega)$ измерима. Определим $\xi_n(omega) = \frac {k}n$, подобрав для каждого $n$ $k$ так, чтобы $\frac kn\le \xi(\omega)\le \frac{k+1}n$. Тогда $|\xi - \xi_n| \le \frac1n$ и
\[
  \E\xi = \int\limits_\Omega \xi(\omega) \P(d\omega) = \lim\limits_{n\to\infty} \rY k{-\infty} \frac kn \P\left\{\frac kn\le\xi(\omega)< \frac{k+1}n\right\}.
\]

Не забудем следущее: предел функций $\xi_n(\omega)$ должен быть измерим.

Если мат ожидания вычислять таким предельным переходом, мы далеко не уйдём. На следующей лекции расскажу, как их считать.